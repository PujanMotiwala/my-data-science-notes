#### _Autoencoders_

>Autoencoders leverage [neural networks](https://www.ibm.com/topics/neural-networks "neural-networks") to compress data and then recreate a new representation of the original data’s input. Looking at the image below, you can see that the hidden layer specifically acts as a bottleneck to compress the input layer prior to reconstructing within the output layer. The stage from the input layer to the hidden layer is referred to as “encoding” while the stage from the hidden layer to the output layer is known as “decoding.”

OR

>Autoencoder is a type of neural network architecture that is used for unsupervised learning, dimensionality reduction and feature learning. Autoencoder is composed of two main parts: an encoder and a decoder. The encoder is used to compress the input data into a lower-dimensional representation called the bottleneck or latent representation, and the decoder is used to reconstruct the input data from the bottleneck representation.\

## TAGS
[[ML model]] [[Unsupervised]] [[Autoencoder]]