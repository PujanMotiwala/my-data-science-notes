{
	"nodes":[
		{"id":"68c4575c4df41494","type":"text","text":"[[Categorical (Qualitative data)]]","x":-1140,"y":-170,"width":200,"height":90},
		{"id":"3356954ef93f50cd","type":"text","text":"Independent | Features (X)","x":-1480,"y":-155,"width":250,"height":60},
		{"id":"58c210d7a4836f03","type":"text","text":"Dependent | Target (y)","x":-1480,"y":-20,"width":250,"height":60},
		{"id":"3afcf8b237482531","type":"text","text":"[[Numeric (Quantitative data)]]","x":-1140,"y":-35,"width":200,"height":90},
		{"id":"059c9d8eeb13610d","type":"text","text":"Mean Comparison","x":-560,"y":180,"width":200,"height":50},
		{"id":"932998f65ca03006","type":"text","text":"Independent | Features (X)","x":-1480,"y":515,"width":250,"height":60},
		{"id":"31b21cf2b368ae40","type":"text","text":"Dependent | Target (y)","x":-1480,"y":650,"width":250,"height":60},
		{"id":"1bbc808a2365d784","type":"text","text":"1 X","x":-800,"y":590,"width":200,"height":50},
		{"id":"1b4867c785e0dff1","type":"text","text":"Independent | Features (X)","x":-1480,"y":875,"width":250,"height":60},
		{"id":"aebd360f430e6c33","type":"text","text":"Dependent | Target (y)","x":-1480,"y":1010,"width":250,"height":60},
		{"id":"d5396ddaaf5941bc","type":"text","text":"","x":-800,"y":950,"width":200,"height":50},
		{"id":"cfd53486b8568646","type":"text","text":"[[Numeric (Quantitative data)]]","x":-1140,"y":195,"width":200,"height":90},
		{"id":"b3baf570b476e962","type":"text","text":"Independent | Features (X)","x":-1480,"y":210,"width":250,"height":60},
		{"id":"3521f82809c8b256","type":"text","text":"Dependent | Target (y)","x":-1480,"y":345,"width":250,"height":60},
		{"id":"acb4ae9170576faf","type":"text","text":"[[Categorical (Qualitative data)]]","x":-1140,"y":330,"width":200,"height":90},
		{"id":"ee187554eabec001","type":"text","text":"[[Numeric (Quantitative data)]]","x":-1140,"y":570,"width":200,"height":90},
		{"id":"85f2b0701fb7d683","type":"text","text":"[[Categorical (Qualitative data)]]","x":-1140,"y":930,"width":200,"height":90},
		{"id":"b91c56ab20879570","type":"text","text":"Logistic Regression","x":-800,"y":285,"width":200,"height":50},
		{"id":"022dd768c670a30f","type":"text","text":"More than 1 X","x":-800,"y":515,"width":200,"height":50},
		{"id":"7b72ff3e7685c0d8","type":"text","text":"1 Sided\n- Directional (A > B or B > A)\n- Tests if one group mean is either greater than or less than the other group mean.","x":0,"y":-620,"width":300,"height":180},
		{"id":"06514a9e1f3fa71b","type":"text","text":"2 Sided\n- Non Directional\n- Tests if there is any difference between two group means, regardless of direction.","x":0,"y":-420,"width":300,"height":190},
		{"id":"3f5e582a63eb8c74","type":"text","text":"Paired\n- Compares means of paired observations\n- Ex: A person's blood pressure Before-and-After treatment, A student marks Before-and-After educational intervention   ","x":500,"y":-535,"width":400,"height":190},
		{"id":"f505538b9294f67a","type":"text","text":"2 Sample | Independent t test\n- Compares means of 2 independent groups.\n- Assume : Equal variance\n- Ex: The average daily sodium intake of adults in City A differs from that in City B. ","x":500,"y":-307,"width":400,"height":207},
		{"id":"510ddfb7bea963b2","type":"text","text":"1 Sample\n- Compares one group's mean to a known value.\n- Ex: The average daily sodium intake of adults in a city differs from the recommended intake.","x":500,"y":-780,"width":400,"height":200},
		{"id":"b53507203790c35d","type":"text","text":"Pooled Variance t-test (2 Sample)\n- Assume : Equal variance","x":1100,"y":-303,"width":340,"height":100},
		{"id":"04ef2c77bd7d0ed1","type":"text","text":"Welch's t-test (2 Sample)\n- Adjusts well for unequal variance","x":1100,"y":-180,"width":340,"height":100},
		{"id":"432f80bd4a46512d","type":"text","text":"t test \n- A test to compare two group means for significant difference.","x":-280,"y":-510,"width":220,"height":165},
		{"id":"429ef8e68bc9831b","type":"text","text":"Mean Comparison","x":-860,"y":-80,"width":200,"height":50},
		{"id":"a572e4a19d5b070b","type":"text","text":"Only 2 groups - A & B","x":-600,"y":-280,"width":228,"height":50},
		{"id":"640dec1875ea1b93","type":"text","text":"3 or more groups","x":-588,"y":-30,"width":228,"height":50},
		{"id":"a76025bd40d56b48","type":"text","text":"Analysis of Variance \n(ANOVA) ","x":-280,"y":-43,"width":220,"height":77},
		{"id":"53ec8b507dd5fe32","x":-165,"y":418,"width":250,"height":60,"type":"text","text":""},
		{"id":"eacbdbc4f01e26eb","x":-1160,"y":3320,"width":1280,"height":1560,"type":"text","text":"# Comprehensive Machine Learning Methods and Use Cases\n\n| Category                 | Methods                                                                                                                                                    | When to Use                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n| ------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Regression               | • Linear (Simple/Multiple)<br>• Polynomial<br>• Ridge/Lasso/Elastic Net<br>• Logistic<br>• Poisson/Negative Binomial<br>• Quantile<br>• GAM                | • Linear: Continuous output, linear relationship, interpretability needed<br>• Polynomial: Non-linear continuous relationships<br>• Ridge/Lasso/Elastic Net: Many features, multicollinearity, prevent overfitting<br>• Logistic: Binary/categorical output, probability estimation<br>• Poisson/Negative Binomial: Count data, exposure variable present<br>• Quantile: Modeling specific parts of distribution, robust to outliers<br>• GAM: Complex non-linear relationships, interpretability needed                                                                                     |\n| Classification           | • Logistic Regression<br>• Decision Trees/Random Forest<br>• SVM<br>• Naive Bayes<br>• KNN<br>• Gradient Boosting (XGBoost, LightGBM)<br>• Neural Networks | • Logistic: Binary/multi-class, linearly separable, probability needed<br>• Trees/Forest: Non-linear boundaries, feature importance, handling mixed data types<br>• SVM: High-dimensional data, clear margin of separation, kernel trick for non-linearity<br>• Naive Bayes: Text classification, real-time prediction, probabilistic output<br>• KNN: Simple implementation, non-linear boundaries, lazy learning<br>• Gradient Boosting: High performance, handle imbalanced data, feature interactions<br>• Neural Networks: Complex patterns, large datasets, automatic feature learning |\n| Clustering               | • K-Means<br>• Hierarchical<br>• DBSCAN<br>• Gaussian Mixture Models<br>• OPTICS<br>• Spectral Clustering                                                  | • K-Means: Spherical clusters, known number of clusters, large datasets<br>• Hierarchical: Unknown number of clusters, hierarchical structure needed<br>• DBSCAN: Arbitrary shaped clusters, noisy data, unknown number of clusters<br>• GMM: Overlapping clusters, soft clustering, probabilistic membership<br>• OPTICS: Varying density clusters, hierarchical density-based clustering<br>• Spectral: Non-convex clusters, graph-based data                                                                                                                                              |\n| Dimensionality Reduction | • PCA<br>• t-SNE<br>• UMAP<br>• LDA<br>• Autoencoders<br>• NMF                                                                                             | • PCA: Linear dimensionality reduction, feature extraction, variance preservation<br>• t-SNE: Non-linear reduction, visualization of high-dimensional data<br>• UMAP: Faster alternative to t-SNE, better preservation of global structure<br>• LDA: Supervised reduction, classification tasks, maximizing class separability<br>• Autoencoders: Non-linear reduction, feature learning, anomaly detection<br>• NMF: Non-negative data, interpretable features, topic modeling                                                                                                              |\n| Time Series              | • ARIMA/SARIMA<br>• Prophet<br>• LSTM/GRU<br>• Exponential Smoothing<br>• GARCH<br>• State Space Models                                                    | • ARIMA: Stationary data, clear trend/seasonality, short to medium-term forecasting<br>• Prophet: Strong seasonality, missing data, multiple seasonalities, outlier robust<br>• LSTM/GRU: Complex patterns, long-term dependencies, sequential data<br>• Exp. Smoothing: Short-term forecasting, clear trend and/or seasonality<br>• GARCH: Volatility modeling, heteroskedastic time series<br>• State Space: Complex dynamics, unobserved components, Kalman filtering                                                                                                                     |\n| Association Rules        | • Apriori<br>• FP-Growth<br>• ECLAT                                                                                                                        | • Apriori: Transactional data, low min. support, easy to understand<br>• FP-Growth: Large datasets, frequent pattern mining, memory efficient<br>• ECLAT: Vertical data format, faster than Apriori for some datasets                                                                                                                                                                                                                                                                                                                                                                        |\n| Semi-Supervised          | • Label Propagation<br>• Self-Training<br>• Co-Training<br>• Tri-Training                                                                                  | • Label Propagation: Partially labeled data, assuming similarity implies same label<br>• Self-Training: Limited labeled data, confident predictions, iterative labeling<br>• Co-Training: Two independent views of data, complementary information<br>• Tri-Training: Improved generalization over self-training, reduces bias                                                                                                                                                                                                                                                               |\n| Reinforcement Learning   | • Q-Learning<br>• Policy Gradient<br>• DQN<br>• A3C<br>• PPO                                                                                               | • Q-Learning: Discrete action spaces, model-free learning, value-based<br>• Policy Gradient: Continuous action spaces, direct policy optimization<br>• DQN: High-dimensional state spaces, stable learning in neural networks<br>• A3C: Parallel training, continuous or discrete actions, improved stability<br>• PPO: Stable policy optimization, good for continuous control tasks                                                                                                                                                                                                        |\n| Deep Learning            | • CNN<br>• RNN/LSTM/GRU<br>• Transformers<br>• GANs<br>• VAEs<br>• Graph Neural Networks                                                                   | • CNN: Image data, spatial patterns, feature hierarchy learning<br>• RNN/LSTM/GRU: Sequential data, time series, variable length inputs<br>• Transformers: NLP tasks, long-range dependencies, parallelizable<br>• GANs: Generative tasks, image synthesis, domain transfer<br>• VAEs: Generative modeling, probabilistic latent variables, data reconstruction<br>• GNNs: Graph-structured data, node classification, link prediction                                                                                                                                                       |\n| Anomaly Detection        | • Isolation Forest<br>• One-Class SVM<br>• Autoencoders<br>• LOF                                                                                           | • Isolation Forest: Unsupervised, handles high-dimensional data efficiently<br>• One-Class SVM: When normal behavior can be tightly bounded<br>• Autoencoders: Complex data, reconstruction-based detection<br>• LOF: Local density-based detection, varying densities in data                                                                                                                                                                                                                                                                                                               |\n\nNotes:\n- Method selection depends on data characteristics, problem type, and specific requirements (e.g., interpretability, speed, scalability).\n- Consider computational resources, data size, and model complexity when choosing a method.\n- Ensemble methods and hybrid approaches can often outperform single models.\n- Always validate assumptions, perform proper model evaluation, and consider the bias-variance tradeoff.\n- This matrix serves as a starting point; always refer to latest research for cutting-edge methods in each category."},
		{"id":"f873c4fd8a9f2bb7","x":-860,"y":1070,"width":1040,"height":1150,"type":"text","text":"# Compressed Statistical and Machine Learning Methods Matrix\n\n| Input Type                      | Output Type | Condition/Context         | Methods                                              |\n| ------------------------------- | ----------- | ------------------------- | ---------------------------------------------------- |\n| Numerical (Single/Multiple)     | Numerical   | Linear relationship       | Linear Regression                                    |\n|                                 |             | Correlation               | Pearson's r                                          |\n|                                 |             | Non-linear relationship   | Spearman's Rank Correlation, Polynomial Regression   |\n|                                 |             | Dimensionality Reduction  | PCA, t-SNE                                           |\n|                                 |             | Clustering                | K-means, Hierarchical Clustering                     |\n|                                 |             | Time Series               | ARIMA, SARIMA, Prophet                               |\n| Numerical (Single/Multiple)     | Categorical | Binary outcome            | Logistic Regression                                  |\n|                                 |             | Non-binary outcome        | Multinomial Logistic Regression                      |\n|                                 |             | Classification            | SVM, Naive Bayes, Random Forest, Gradient Boosting   |\n|                                 |             | Semi-supervised           | Label Propagation                                    |\n| Categorical (Single/Multiple)   | Numerical   | Two groups                | t-test, Wilcoxon Rank-Sum Test                       |\n|                                 |             | More than two groups      | ANOVA, Kruskal-Wallis Test                           |\n|                                 |             | Dimensionality Reduction  | PCA, t-SNE                                           |\n|                                 |             | Clustering                | K-means, Hierarchical Clustering                     |\n| Categorical (Single/Multiple)   | Categorical | Large sample size         | Chi-Square Test                                      |\n|                                 |             | Small sample size         | Fisher's Exact Test                                  |\n|                                 |             | Association               | Apriori, FP-Growth                                   |\n|                                 |             | Binary/Non-binary outcome | Logistic Regression, Multinomial Logistic Regression |\n| Mixed (Numerical & Categorical) | Numerical   | Parametric                | Linear Regression, Generalized Linear Models         |\n|                                 |             | Non-parametric            | Random Forest, Gradient Boosting                     |\n|                                 |             | Dimensionality Reduction  | PCA, t-SNE                                           |\n|                                 |             | Clustering                | K-means, Hierarchical Clustering                     |\n| Mixed (Numerical & Categorical) | Categorical | Binary/Non-binary outcome | Logistic Regression, Generalized Linear Models       |\n|                                 |             | Classification            | Random Forest, Gradient Boosting, SVM                |\n|                                 |             | Semi-supervised           | Label Propagation                                    |\n\nNotes:\n- Time Series analysis methods are included for temporal data.\n- Cross-validation and model evaluation techniques (e.g., k-fold CV, holdout method) should be applied as appropriate for all predictive modeling tasks.\n- The choice of method may depend on additional factors such as sample size, data distribution, and specific research questions."}
	],
	"edges":[
		{"id":"17ad743c983e36eb","fromNode":"3356954ef93f50cd","fromSide":"right","toNode":"68c4575c4df41494","toSide":"left"},
		{"id":"bcf870d281b2db2a","fromNode":"58c210d7a4836f03","fromSide":"right","toNode":"3afcf8b237482531","toSide":"left"},
		{"id":"e77e94ef2c7bdbc4","fromNode":"68c4575c4df41494","fromSide":"right","toNode":"429ef8e68bc9831b","toSide":"left"},
		{"id":"ae4b58f607c16e4a","fromNode":"3afcf8b237482531","fromSide":"right","toNode":"429ef8e68bc9831b","toSide":"left"},
		{"id":"32f6b1fc94f78998","fromNode":"31b21cf2b368ae40","fromSide":"right","toNode":"ee187554eabec001","toSide":"left"},
		{"id":"76564f8785ad3eb2","fromNode":"ee187554eabec001","fromSide":"right","toNode":"1bbc808a2365d784","toSide":"left"},
		{"id":"658b39d90d02660a","fromNode":"85f2b0701fb7d683","fromSide":"right","toNode":"d5396ddaaf5941bc","toSide":"left"},
		{"id":"94c31237bba810f8","fromNode":"1b4867c785e0dff1","fromSide":"right","toNode":"85f2b0701fb7d683","toSide":"left"},
		{"id":"ae223305f7ea5196","fromNode":"b3baf570b476e962","fromSide":"right","toNode":"cfd53486b8568646","toSide":"left"},
		{"id":"f09807cf602165e4","fromNode":"3521f82809c8b256","fromSide":"right","toNode":"acb4ae9170576faf","toSide":"left"},
		{"id":"d4db15cb4cddddf2","fromNode":"aebd360f430e6c33","fromSide":"right","toNode":"85f2b0701fb7d683","toSide":"left"},
		{"id":"7c66209ca8523734","fromNode":"932998f65ca03006","fromSide":"right","toNode":"ee187554eabec001","toSide":"left"},
		{"id":"039b3d164891abd3","fromNode":"cfd53486b8568646","fromSide":"right","toNode":"b91c56ab20879570","toSide":"left"},
		{"id":"92fe10fa20dd8b49","fromNode":"acb4ae9170576faf","fromSide":"right","toNode":"b91c56ab20879570","toSide":"left"},
		{"id":"44f980be612c2d4e","fromNode":"7b72ff3e7685c0d8","fromSide":"right","toNode":"f505538b9294f67a","toSide":"left"},
		{"id":"65e8907881415bda","fromNode":"7b72ff3e7685c0d8","fromSide":"right","toNode":"3f5e582a63eb8c74","toSide":"left"},
		{"id":"ebe3aedbcfaef950","fromNode":"7b72ff3e7685c0d8","fromSide":"right","toNode":"510ddfb7bea963b2","toSide":"left"},
		{"id":"67c763e584491996","fromNode":"06514a9e1f3fa71b","fromSide":"right","toNode":"f505538b9294f67a","toSide":"left"},
		{"id":"9760f19a4e2efc6a","fromNode":"06514a9e1f3fa71b","fromSide":"right","toNode":"3f5e582a63eb8c74","toSide":"left"},
		{"id":"f0e1a6efa69c2638","fromNode":"06514a9e1f3fa71b","fromSide":"right","toNode":"510ddfb7bea963b2","toSide":"left"},
		{"id":"5d9214b5c4945124","fromNode":"f505538b9294f67a","fromSide":"right","toNode":"b53507203790c35d","toSide":"left"},
		{"id":"66cb6baf3c5d2bd5","fromNode":"f505538b9294f67a","fromSide":"right","toNode":"04ef2c77bd7d0ed1","toSide":"left"},
		{"id":"371cbda7c549ad14","fromNode":"429ef8e68bc9831b","fromSide":"right","toNode":"a572e4a19d5b070b","toSide":"left"},
		{"id":"48c55674b5ad71ca","fromNode":"a572e4a19d5b070b","fromSide":"right","toNode":"432f80bd4a46512d","toSide":"left"},
		{"id":"a6fd22282764b8c1","fromNode":"432f80bd4a46512d","fromSide":"right","toNode":"7b72ff3e7685c0d8","toSide":"left"},
		{"id":"33aed49cd928aaa3","fromNode":"432f80bd4a46512d","fromSide":"right","toNode":"06514a9e1f3fa71b","toSide":"left"},
		{"id":"ce1e095145cc1193","fromNode":"429ef8e68bc9831b","fromSide":"right","toNode":"640dec1875ea1b93","toSide":"left"},
		{"id":"4cec1de8118f14be","fromNode":"640dec1875ea1b93","fromSide":"right","toNode":"a76025bd40d56b48","toSide":"left"}
	]
}